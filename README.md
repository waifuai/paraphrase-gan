# API-Based Paraphrase Prompt Refinement (OpenRouter default)

This project can use either OpenRouter or Google Gemini to iteratively generate paraphrases and refine the generation prompt based on classification feedback. OpenRouter is the default provider.

Core Idea: A loop generates paraphrases for input phrases using a dynamic prompt, classifies them (human vs machine), and then refines the generator prompt for the next iteration based on the classification results.

Default Provider and Model Files:
- ~/.model-openrouter: model id for OpenRouter (default: openrouter/horizon-beta)
- ~/.model-gemini: model id for Gemini (default: gemini-2.5-pro)

Provider Selection:
- PROVIDER env var controls provider: "openrouter" (default) or "gemini"

Credentials:
- OpenRouter: OPENROUTER_API_KEY or ~/.api-openrouter
- Gemini: GEMINI_API_KEY or GOOGLE_API_KEY or ~/.api-gemini

Gemini SDK remains available via google-genai when PROVIDER=gemini.

## Project Structure

-   `src/`: Contains the main source code.
    -   `main.py`: The main script for running the prompt refinement workflow. Handles setup, API key loading, Gemini client initialization, data loading, and the main loop execution.
    -   `prompt_loop.py`: Contains the logic for a single iteration of the refinement loop (`run_prompt_refinement_iteration`), including generation, classification, result processing, and calling the prompt refinement logic.
    -   `utils.py`: Contains helper functions for interacting with the Gemini API (`gemini_generate_paraphrase`, `gemini_classify_paraphrase`), API key loading, directory creation, logging setup, mock data generation (`generate_mock_paraphrases`), and post-processing classifications (`postprocess_discriminator_output_gemini`).
    -   `config.py`: Holds configuration settings (paths, filenames, Gemini model details, API key location, prompt templates, loop control parameters) and the placeholder prompt refinement function (`refine_generator_prompt`).
    -   `tests/`: Contains unit tests (needs updating for Gemini approach).
        -   `test_gan.py`: (Needs renaming/refactoring) Unit tests for various components.
        -   `conftest.py`: Defines pytest fixtures.
-   `plans/`: Contains markdown files outlining development plans (e.g., `1-hf-migration-plan.md` - now outdated).
-   `lessons/`: Contains markdown files documenting lessons learned.
-   `data/`: Contains data used and generated by the loop.
    -   `raw/`: Input data (e.g., `mock_input_phrases.tsv`).
    -   `processed/`: Data generated during the loop.
        -   `selected/`: Selected paraphrases classified as 'human' (e.g., `selected_paraphrases_1.tsv`).
        -   `prompts/`: History of generator prompts used (e.g., `generator_prompt_1.txt`).
        -   `loop_results_1.json`: JSON file summarizing metrics for each iteration.
-   `logs/`: Stores log files (e.g., `run_gemini.log`).
-   `.api-gemini`: **(Important/Ignored)** File containing your Google Gemini API key (should be placed in your home directory by default, as configured in `src/config.py`).

## Setup and Installation

1.  **Prerequisites:**
    *   Python 3.8 or higher
    *   `pip`
    *   Git
    *   `uv` (Optional, but recommended for environment management as per instructions)
    *   Google Gemini API Key: Obtain an API key from Google AI Studio (https://aistudio.google.com/app/apikey).

2.  **Clone the repository:**

    ```bash
    git clone <repository_url>
    cd <repository_directory>
    ```

3.  **Create and activate a virtual environment:**

    ```bash
    # Using uv (recommended based on instructions)
    # Ensure uv is installed (e.g., pip install uv or python -m pip install uv)
    python -m uv venv .venv
    # Activate:
    # Linux/macOS: source .venv/bin/activate
    # Windows: .venv\Scripts\activate

    # OR using standard venv
    # python -m venv .venv
    # Activate:
    # Linux/macOS: source .venv/bin/activate
    # Windows: .venv\Scripts\activate
    ```

4.  Install dependencies:

    ```bash
    .venv/Scripts/python.exe -m uv pip install -r requirements.txt
    # For contributors/CI
    .venv/Scripts/python.exe -m uv pip install -r requirements-dev.txt
    ```
    The requirements now use the Google GenAI SDK (google-genai) and split runtime vs dev.

5.  Set up API Keys (env-first with file fallback):
- OpenRouter (default provider):
  export OPENROUTER_API_KEY="your_key_here"
  or create ~/.api-openrouter with the key only.
- Gemini (when PROVIDER=gemini):
  export GEMINI_API_KEY="your_key_here"
  or export GOOGLE_API_KEY
  or create ~/.api-gemini with the key only.

6.  Select Provider and Model:
- Default is OpenRouter; to force Gemini:
  export PROVIDER=gemini
- Model resolution:
  echo "openrouter/horizon-beta" > ~/.model-openrouter
  echo "gemini-2.5-pro" > ~/.model-gemini
  If files are absent, defaults are used.

## Usage

### Running the Prompt Refinement Loop

The main script (`src/main.py`) orchestrates the workflow:

1.  **Initialization:**
    *   Creates necessary directories.
    *   Loads the Gemini API key.
    *   Configures the `google-generativeai` client.
    *   Loads input phrases from `data/raw/mock_input_phrases.tsv` or generates mock data if the file doesn't exist.

2.  **Prompt Refinement Loop:**
    *   Starts with the initial generator prompt defined in `src/config.py`.
    *   Iterates for a configured number of times (`loop_control.max_iterations`).
    *   In each iteration (`run_prompt_refinement_iteration` in `src/prompt_loop.py`):
        *   Processes input phrases in batches.
        *   For each phrase:
            *   Calls the Gemini API using the *current generator prompt* to generate a paraphrase (`gemini_generate_paraphrase`).
            *   If generation succeeds, calls the Gemini API using the *classification prompt* to classify the paraphrase as 'human' or 'machine' (`gemini_classify_paraphrase`).
        *   Collects all results (input, generated text, classification).
        *   Filters the results to get pairs classified as 'human' (`postprocess_discriminator_output_gemini`).
        *   Saves the selected pairs to a TSV file in `data/processed/selected/`.
        *   Calculates and logs summary metrics for the iteration (generation rate, selection rate, etc.). Saves summary to a JSON file in `data/processed/`.
        *   Saves the generator prompt used for the current iteration to `data/processed/prompts/`.
        *   Calls the `refine_generator_prompt` function (from `src/config.py`) to potentially modify the generator prompt based on the iteration's results.
        *   Uses the (potentially) refined prompt for the *next* iteration.

To run the loop, execute the following command from the project root directory:

```bash
# Ensure your virtual environment is activated
python -m src.main
```

The script will run for the configured number of iterations, making calls to the Gemini API. Monitor your API usage and costs. Stop with Ctrl+C if needed.

### Testing

The `src/tests/` directory contains unit tests. **Note:** These tests need significant updates to reflect the Gemini API approach and remove obsolete Hugging Face tests. Mocking API calls will be essential for reliable testing without actual API usage.

To run the existing (likely outdated) tests:

```bash
# Ensure your virtual environment is activated
python -m pytest src/tests/
```

## Core Components (Gemini Version)

-   **`main.py`:** Main script, setup, loop orchestration.
-   **`prompt_loop.py`:** Logic for a single refinement iteration.
-   **`utils.py`:** Gemini API wrappers, helpers, mock data generation.
-   **`config.py`:** Configuration, initial prompts, refinement logic placeholder.
-   Google GenAI SDK (google-genai): The core library for interacting with the Gemini API using a centralized client.
-   **`pandas`:** Used for handling input data and saving results.

## Key Changes from Previous (HF GAN) Version

-   Replaced all Hugging Face `transformers`, `datasets`, `Trainer` components with direct calls to the Google Gemini API via `google-generativeai`.
-   Removed local model training entirely.
-   Focus shifted from model weight updates to iterative *prompt refinement*.
-   Removed `src/model_utils.py` and `src/data_utils.py`.
-   Renamed `src/gan.py` to `src/prompt_loop.py`.
-   Updated `requirements.txt`.
-   Updated `src/config.py` with Gemini-specific settings and prompt templates.
-   Rewrote `src/main.py` and created `src/prompt_loop.py` for the new workflow.
-   Updated `src/utils.py` with Gemini API functions.
-   Requires a Gemini API key setup.
-   Tests need significant refactoring.

## Further Improvements

-   **Implement Prompt Refinement Logic:** Develop actual strategies in `config.py:refine_generator_prompt` based on iteration results (e.g., analyze rejected phrases, adjust instructions).
-   **Error Handling:** Enhance error handling for API calls (rate limits, specific errors).
-   **Input Data:** Use more diverse and realistic input phrases instead of basic mock data.
-   **Advanced Classification:** Improve the classification prompt or use more robust methods if simple 'human'/'machine' is insufficient.
-   **Metrics:** Track more detailed metrics (e.g., semantic similarity between input and selected paraphrase).
-   **Testing:** Implement comprehensive tests with API mocking.
-   **Configuration:** Move prompts to separate files for easier management.
-   **Cost Management:** Add checks or limits based on estimated API costs.
