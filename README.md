# Gemini API-Based Paraphrase Prompt Refinement

This project uses the Google Gemini API to iteratively generate paraphrases and refine the generation prompt based on classification feedback. Instead of training local models, it focuses on prompt engineering.

**Core Idea:** A loop generates paraphrases for input phrases using a dynamic prompt, classifies them using another Gemini prompt (human vs. machine), and then refines the *generator prompt* for the next iteration based on the classification results.

**Gemini Model Used:** Configured in `src/config.py` (e.g., `gemini-2.5-flash-preview-04-17`)

## Project Structure

-   `src/`: Contains the main source code.
    -   `main.py`: The main script for running the prompt refinement workflow. Handles setup, API key loading, Gemini client initialization, data loading, and the main loop execution.
    -   `prompt_loop.py`: Contains the logic for a single iteration of the refinement loop (`run_prompt_refinement_iteration`), including generation, classification, result processing, and calling the prompt refinement logic.
    -   `utils.py`: Contains helper functions for interacting with the Gemini API (`gemini_generate_paraphrase`, `gemini_classify_paraphrase`), API key loading, directory creation, logging setup, mock data generation (`generate_mock_paraphrases`), and post-processing classifications (`postprocess_discriminator_output_gemini`).
    -   `config.py`: Holds configuration settings (paths, filenames, Gemini model details, API key location, prompt templates, loop control parameters) and the placeholder prompt refinement function (`refine_generator_prompt`).
    -   `tests/`: Contains unit tests (needs updating for Gemini approach).
        -   `test_gan.py`: (Needs renaming/refactoring) Unit tests for various components.
        -   `conftest.py`: Defines pytest fixtures.
-   `plans/`: Contains markdown files outlining development plans (e.g., `1-hf-migration-plan.md` - now outdated).
-   `lessons/`: Contains markdown files documenting lessons learned.
-   `data/`: Contains data used and generated by the loop.
    -   `raw/`: Input data (e.g., `mock_input_phrases.tsv`).
    -   `processed/`: Data generated during the loop.
        -   `selected/`: Selected paraphrases classified as 'human' (e.g., `selected_paraphrases_1.tsv`).
        -   `prompts/`: History of generator prompts used (e.g., `generator_prompt_1.txt`).
        -   `loop_results_1.json`: JSON file summarizing metrics for each iteration.
-   `logs/`: Stores log files (e.g., `run_gemini.log`).
-   `.api-gemini`: **(Important/Ignored)** File containing your Google Gemini API key (should be placed in your home directory by default, as configured in `src/config.py`).

## Setup and Installation

1.  **Prerequisites:**
    *   Python 3.8 or higher
    *   `pip`
    *   Git
    *   `uv` (Optional, but recommended for environment management as per instructions)
    *   **Google Gemini API Key:** Obtain an API key from Google AI Studio ([https://aistudio.google.com/app/apikey](https://aistudio.google.com/app/apikey)).

2.  **Clone the repository:**

    ```bash
    git clone <repository_url>
    cd <repository_directory>
    ```

3.  **Create and activate a virtual environment:**

    ```bash
    # Using uv (recommended based on instructions)
    # Ensure uv is installed (e.g., pip install uv or python -m pip install uv)
    python -m uv venv .venv
    # Activate:
    # Linux/macOS: source .venv/bin/activate
    # Windows: .venv\Scripts\activate

    # OR using standard venv
    # python -m venv .venv
    # Activate:
    # Linux/macOS: source .venv/bin/activate
    # Windows: .venv\Scripts\activate
    ```

4.  **Install dependencies:**

    ```bash
    # Ensure your virtual environment is activated
    # Using uv (recommended)
    python -m uv pip install -r requirements.txt

    # OR using pip
    # python -m pip install -r requirements.txt
    ```
    The `requirements.txt` file includes: `pytest`, `pandas`, `numpy`, `google-generativeai`, `pathlib`.

5.  **Set up API Key:**
    *   Create a file named `.api-gemini` in your home directory (e.g., `C:/Users/YourUser/.api-gemini` on Windows, `~/.api-gemini` on Linux/macOS).
    *   Paste your Gemini API key into this file and save it.
    *   **Ensure this file is added to your global `.gitignore` or the project's `.gitignore` to prevent accidentally committing your key.** (The project `.gitignore` should be updated).

## Usage

### Running the Prompt Refinement Loop

The main script (`src/main.py`) orchestrates the workflow:

1.  **Initialization:**
    *   Creates necessary directories.
    *   Loads the Gemini API key.
    *   Configures the `google-generativeai` client.
    *   Loads input phrases from `data/raw/mock_input_phrases.tsv` or generates mock data if the file doesn't exist.

2.  **Prompt Refinement Loop:**
    *   Starts with the initial generator prompt defined in `src/config.py`.
    *   Iterates for a configured number of times (`loop_control.max_iterations`).
    *   In each iteration (`run_prompt_refinement_iteration` in `src/prompt_loop.py`):
        *   Processes input phrases in batches.
        *   For each phrase:
            *   Calls the Gemini API using the *current generator prompt* to generate a paraphrase (`gemini_generate_paraphrase`).
            *   If generation succeeds, calls the Gemini API using the *classification prompt* to classify the paraphrase as 'human' or 'machine' (`gemini_classify_paraphrase`).
        *   Collects all results (input, generated text, classification).
        *   Filters the results to get pairs classified as 'human' (`postprocess_discriminator_output_gemini`).
        *   Saves the selected pairs to a TSV file in `data/processed/selected/`.
        *   Calculates and logs summary metrics for the iteration (generation rate, selection rate, etc.). Saves summary to a JSON file in `data/processed/`.
        *   Saves the generator prompt used for the current iteration to `data/processed/prompts/`.
        *   Calls the `refine_generator_prompt` function (from `src/config.py`) to potentially modify the generator prompt based on the iteration's results.
        *   Uses the (potentially) refined prompt for the *next* iteration.

To run the loop, execute the following command from the project root directory:

```bash
# Ensure your virtual environment is activated
python -m src.main
```

The script will run for the configured number of iterations, making calls to the Gemini API. Monitor your API usage and costs. Stop with Ctrl+C if needed.

### Testing

The `src/tests/` directory contains unit tests. **Note:** These tests need significant updates to reflect the Gemini API approach and remove obsolete Hugging Face tests. Mocking API calls will be essential for reliable testing without actual API usage.

To run the existing (likely outdated) tests:

```bash
# Ensure your virtual environment is activated
python -m pytest src/tests/
```

## Core Components (Gemini Version)

-   **`main.py`:** Main script, setup, loop orchestration.
-   **`prompt_loop.py`:** Logic for a single refinement iteration.
-   **`utils.py`:** Gemini API wrappers, helpers, mock data generation.
-   **`config.py`:** Configuration, initial prompts, refinement logic placeholder.
-   **`google-generativeai`:** The core library for interacting with the Gemini API.
-   **`pandas`:** Used for handling input data and saving results.

## Key Changes from Previous (HF GAN) Version

-   Replaced all Hugging Face `transformers`, `datasets`, `Trainer` components with direct calls to the Google Gemini API via `google-generativeai`.
-   Removed local model training entirely.
-   Focus shifted from model weight updates to iterative *prompt refinement*.
-   Removed `src/model_utils.py` and `src/data_utils.py`.
-   Renamed `src/gan.py` to `src/prompt_loop.py`.
-   Updated `requirements.txt`.
-   Updated `src/config.py` with Gemini-specific settings and prompt templates.
-   Rewrote `src/main.py` and created `src/prompt_loop.py` for the new workflow.
-   Updated `src/utils.py` with Gemini API functions.
-   Requires a Gemini API key setup.
-   Tests need significant refactoring.

## Further Improvements

-   **Implement Prompt Refinement Logic:** Develop actual strategies in `config.py:refine_generator_prompt` based on iteration results (e.g., analyze rejected phrases, adjust instructions).
-   **Error Handling:** Enhance error handling for API calls (rate limits, specific errors).
-   **Input Data:** Use more diverse and realistic input phrases instead of basic mock data.
-   **Advanced Classification:** Improve the classification prompt or use more robust methods if simple 'human'/'machine' is insufficient.
-   **Metrics:** Track more detailed metrics (e.g., semantic similarity between input and selected paraphrase).
-   **Testing:** Implement comprehensive tests with API mocking.
-   **Configuration:** Move prompts to separate files for easier management.
-   **Cost Management:** Add checks or limits based on estimated API costs.
